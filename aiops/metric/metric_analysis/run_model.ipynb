{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4343a28f-9f4f-4854-8df6-04833738189e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from access_admin_api import *\n",
    "from model.utils import plt_plot\n",
    "from filter_anomaly_metric import *\n",
    "channel = Channel(host=\"localhost\", port=11090) # url of opni-internal. can port-forward to localhost:11090\n",
    "service = CortexAdminStub(channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3b29479-b758-4d86-8102-0f65961a23b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6165ba24-e496-491d-86f2-6eb083f24f0b'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster = 0\n",
    "cluster_id = (await get_all_users(service))[cluster]\n",
    "cluster_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f83a006c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics = await list_all_metric(service, cluster_id)\n",
    "fixed_ts = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ec6bf70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2023, 4, 18, 23, 9, 28, 933879)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixed_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3decd1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if total_count > 50:\n",
    "#     with open(\"collected_data/\" + str(fixed_ts.timestamp())+user_id+\".data\", 'w') as fout:\n",
    "#         fout.write(json.dumps(imrpove_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b784f61c",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[299], line 2\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmodel\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetric_pattern_classification\u001b[39;00m \u001b[39mimport\u001b[39;00m predict\n",
      "\u001b[0;32m----> 2\u001b[0m res \u001b[39m=\u001b[39m predict(pred_data)\n",
      "\n",
      "File \u001b[0;32m~/workspace/opni/aiops/metric/model/metric_pattern_classification.py:83\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(pred_data)\u001b[0m\n",
      "\u001b[1;32m     81\u001b[0m model \u001b[39m=\u001b[39m MpcModel()\n",
      "\u001b[1;32m     82\u001b[0m model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mto(device)\n",
      "\u001b[0;32m---> 83\u001b[0m model\u001b[39m.\u001b[39mload_state_dict(torch\u001b[39m.\u001b[39;49mload(\u001b[39m\"\u001b[39;49m\u001b[39mmodel.pth\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n",
      "\u001b[1;32m     84\u001b[0m model\u001b[39m.\u001b[39meval()\n",
      "\u001b[1;32m     85\u001b[0m res \u001b[39m=\u001b[39m []\n",
      "\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.6/envs/py38metric/lib/python3.8/site-packages/torch/serialization.py:809\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n",
      "\u001b[1;32m    807\u001b[0m             \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;32m    808\u001b[0m                 \u001b[39mraise\u001b[39;00m pickle\u001b[39m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(e)) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[0;32m--> 809\u001b[0m         \u001b[39mreturn\u001b[39;00m _load(opened_zipfile, map_location, pickle_module, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpickle_load_args)\n",
      "\u001b[1;32m    810\u001b[0m \u001b[39mif\u001b[39;00m weights_only:\n",
      "\u001b[1;32m    811\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.6/envs/py38metric/lib/python3.8/site-packages/torch/serialization.py:1172\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n",
      "\u001b[1;32m   1170\u001b[0m unpickler \u001b[39m=\u001b[39m UnpicklerWrapper(data_file, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n",
      "\u001b[1;32m   1171\u001b[0m unpickler\u001b[39m.\u001b[39mpersistent_load \u001b[39m=\u001b[39m persistent_load\n",
      "\u001b[0;32m-> 1172\u001b[0m result \u001b[39m=\u001b[39m unpickler\u001b[39m.\u001b[39;49mload()\n",
      "\u001b[1;32m   1174\u001b[0m torch\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_validate_loaded_sparse_tensors()\n",
      "\u001b[1;32m   1176\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.6/envs/py38metric/lib/python3.8/site-packages/torch/serialization.py:1142\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n",
      "\u001b[1;32m   1140\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;32m   1141\u001b[0m     nbytes \u001b[39m=\u001b[39m numel \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_element_size(dtype)\n",
      "\u001b[0;32m-> 1142\u001b[0m     typed_storage \u001b[39m=\u001b[39m load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))\n",
      "\u001b[1;32m   1144\u001b[0m \u001b[39mreturn\u001b[39;00m typed_storage\n",
      "\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.6/envs/py38metric/lib/python3.8/site-packages/torch/serialization.py:1116\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n",
      "\u001b[1;32m   1112\u001b[0m storage \u001b[39m=\u001b[39m zip_file\u001b[39m.\u001b[39mget_storage_from_record(name, numel, torch\u001b[39m.\u001b[39mUntypedStorage)\u001b[39m.\u001b[39m_typed_storage()\u001b[39m.\u001b[39m_untyped_storage\n",
      "\u001b[1;32m   1113\u001b[0m \u001b[39m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n",
      "\u001b[1;32m   1114\u001b[0m \u001b[39m# stop wrapping with TypedStorage\u001b[39;00m\n",
      "\u001b[1;32m   1115\u001b[0m typed_storage \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstorage\u001b[39m.\u001b[39mTypedStorage(\n",
      "\u001b[0;32m-> 1116\u001b[0m     wrap_storage\u001b[39m=\u001b[39mrestore_location(storage, location),\n",
      "\u001b[1;32m   1117\u001b[0m     dtype\u001b[39m=\u001b[39mdtype,\n",
      "\u001b[1;32m   1118\u001b[0m     _internal\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;32m   1120\u001b[0m \u001b[39mif\u001b[39;00m typed_storage\u001b[39m.\u001b[39m_data_ptr() \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[1;32m   1121\u001b[0m     loaded_storages[key] \u001b[39m=\u001b[39m typed_storage\n",
      "\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.6/envs/py38metric/lib/python3.8/site-packages/torch/serialization.py:217\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n",
      "\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_restore_location\u001b[39m(storage, location):\n",
      "\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m _, _, fn \u001b[39min\u001b[39;00m _package_registry:\n",
      "\u001b[0;32m--> 217\u001b[0m         result \u001b[39m=\u001b[39m fn(storage, location)\n",
      "\u001b[1;32m    218\u001b[0m         \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;32m    219\u001b[0m             \u001b[39mreturn\u001b[39;00m result\n",
      "\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.6/envs/py38metric/lib/python3.8/site-packages/torch/serialization.py:182\u001b[0m, in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n",
      "\u001b[1;32m    180\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_cuda_deserialize\u001b[39m(obj, location):\n",
      "\u001b[1;32m    181\u001b[0m     \u001b[39mif\u001b[39;00m location\u001b[39m.\u001b[39mstartswith(\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m):\n",
      "\u001b[0;32m--> 182\u001b[0m         device \u001b[39m=\u001b[39m validate_cuda_device(location)\n",
      "\u001b[1;32m    183\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(obj, \u001b[39m\"\u001b[39m\u001b[39m_torch_load_uninitialized\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n",
      "\u001b[1;32m    184\u001b[0m             \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mdevice(device):\n",
      "\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.6/envs/py38metric/lib/python3.8/site-packages/torch/serialization.py:166\u001b[0m, in \u001b[0;36mvalidate_cuda_device\u001b[0;34m(location)\u001b[0m\n",
      "\u001b[1;32m    163\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_get_device_index(location, \u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;32m    165\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available():\n",
      "\u001b[0;32m--> 166\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mAttempting to deserialize object on a CUDA \u001b[39m\u001b[39m'\u001b[39m\n",
      "\u001b[1;32m    167\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mdevice but torch.cuda.is_available() is False. \u001b[39m\u001b[39m'\u001b[39m\n",
      "\u001b[1;32m    168\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mIf you are running on a CPU-only machine, \u001b[39m\u001b[39m'\u001b[39m\n",
      "\u001b[1;32m    169\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mplease use torch.load with map_location=torch.device(\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39mcpu\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m'\u001b[39m\n",
      "\u001b[1;32m    170\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mto map your storages to the CPU.\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32m    171\u001b[0m device_count \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mdevice_count()\n",
      "\u001b[1;32m    172\u001b[0m \u001b[39mif\u001b[39;00m device \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m device_count:\n",
      "\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12a8938f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tybalex/workspace/opni/aiops/metric/metric_analysis/filter_anomaly_metric.py:38: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  _, p_value = ttest_ind(l1, l2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "from dataclasses import asdict, dataclass\n",
    "from datetime import datetime\n",
    "from typing import List\n",
    "\n",
    "# Third Party\n",
    "from filter_anomaly_metric import get_abnormal_metrics\n",
    "from model.metric_pattern_classification import predict\n",
    "\n",
    "BUCKET_NAME = \"metric_ai_jobs\"\n",
    "BUCKET_NAME_RUNS = \"metric_ai_job_runs\"\n",
    "JOB_RUN_DELIMITER = \"=\"\n",
    "JOBRUN_STATUS_SUBMITTED = \"Job Run Submitted\"\n",
    "JOBRUN_STATUS_COMPLETED = \"Job Run Completed\"\n",
    "for ns in [\"default\"]:\n",
    "    res = {}\n",
    "    dashboard_payload_info = []\n",
    "    anomaly_count, total_count = 0, 0\n",
    "    anomaly_metric_list, all_metric_list = await get_abnormal_metrics(\n",
    "        service, cluster_id, fixed_ts, ns\n",
    "    )\n",
    "    anomaly_count += len(anomaly_metric_list)\n",
    "    total_count += len(all_metric_list)\n",
    "    anomaly_metrics_value = [values for pod, metric_name, values in anomaly_metric_list]\n",
    "    preds = predict(anomaly_metrics_value)\n",
    "    \n",
    "    for i, (pod, metric_name, values) in enumerate(anomaly_metric_list):\n",
    "        res[pod + JOB_RUN_DELIMITER + metric_name] = preds[i]\n",
    "        dashboard_payload_info.append((preds[i], pod + JOB_RUN_DELIMITER + metric_name, get_query(metric_name, namespace=ns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11a49f91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('type2_transient_level_up',\n",
       "  'redis-cart-78746d49dc-fvz5h=container_file_descriptors',\n",
       "  'sum(rate(container_file_descriptors{namespace=\"default\"}[2m])) by (pod)')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dashboard_payload_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93d838bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Define the URL for the Grafana API\n",
    "grafana_url = \"http://aa7f185a486744f7ea262a19d7c4bed1-231505684.us-west-1.elb.amazonaws.com:3000/api\"\n",
    "\n",
    "# Set the headers for the API request\n",
    "headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization': 'Bearer eyJrIjoia1Zwbm5Wb2dyazZkSmdEaW56WlhyNjJXNUZraFVMbHgiLCJuIjoiYWRtaW5rZXkiLCJpZCI6MX0='\n",
    "}\n",
    "\n",
    "def remove_dashboard(dashboard_uid):\n",
    "    url = grafana_url + '/dashboards/uid/' + dashboard_uid\n",
    "    # Send the delete request\n",
    "    response = requests.delete(url, headers=headers)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        print('Dashboard deleted successfully')\n",
    "    else:\n",
    "        print('Failed to delete dashboard: {}'.format(response.text))\n",
    "\n",
    "def create_dashboard(dashboard_payload):\n",
    "    # Send a POST request to create the new dashboard\n",
    "    response = requests.post(grafana_url + '/dashboards/db', headers=headers, json=dashboard_payload)\n",
    "\n",
    "    # Verify that the dashboard was created successfully\n",
    "    if response.status_code == 200:\n",
    "        print('Dashboard created successfully')\n",
    "    else:\n",
    "        print('Failed to create dashboard: ' + response.text)\n",
    "\n",
    "\n",
    "# Define the JSON payload for the new dashboard\n",
    "def get_row(title):\n",
    "    row = {\n",
    "      \"datasource\": 'default',\n",
    "      \"gridPos\": {\n",
    "        \"h\": 1,\n",
    "        \"w\": 24,\n",
    "        \"x\": 0,\n",
    "        \"y\": 0\n",
    "      },\n",
    "      \"id\": None,\n",
    "      \"panels\": [],\n",
    "      \"targets\": [\n",
    "        {\n",
    "          \"datasource\": 'default',\n",
    "          \"refId\": \"A\"\n",
    "        }\n",
    "      ],\n",
    "      \"title\": title,\n",
    "      \"type\": \"row\"\n",
    "    }\n",
    "    return row\n",
    "\n",
    "def get_grafana_dashboard_payload(form_payload, dashboard_uid:str, dashboard_title: str=\"Opni-metricAI\", dashboard_tags: List[str]=[\"Opni-metricAI\"]):\n",
    "    \"\"\"\n",
    "    Generate the json format payload for grafana dashboard\n",
    "    params:\n",
    "    @form_payload: List of tuples, each item contains information of a panel in the dashboard - (type_pattern, panel_title, query):\n",
    "                            type_pattern: the pattern predicted from CNN model\n",
    "                            panel_title: title of the panel, contains information of the metric name and pod name\n",
    "                            query: the promQL query for this panel\n",
    "    @dashboard_uid: the unique id of the dashboard, which can be used to identify/create/update/delete the dashboard.\n",
    "    @dashboard_title: a string that is simple the title of the dashboard\n",
    "    @dashboard_tags: List[str], the tags of the dashboard\n",
    "    \"\"\"\n",
    "    panels1, panels2 = [get_row(\"Type1\")], [get_row(\"Type2\")]\n",
    "    for type_pattern, panel_title ,query in form_payload:\n",
    "        ## definition of each panel\n",
    "        p= {\n",
    "                'id': None,\n",
    "                'type': 'graph',\n",
    "                'title': panel_title,\n",
    "                'datasource': 'default',\n",
    "                'targets': [{\n",
    "                    'refId': 'A',\n",
    "                    \"expr\": query\n",
    "                }],\n",
    "                'xaxis': {\n",
    "                    'show': True\n",
    "                },\n",
    "                'yaxes': [{\n",
    "                    'format': 'short',\n",
    "                    'label': 'Count',\n",
    "                    'logBase': 1,\n",
    "                    'max': None,\n",
    "                    'min': 0,\n",
    "                    'show': True\n",
    "                }, {\n",
    "                    'format': 'short',\n",
    "                    'label': None,\n",
    "                    'logBase': 1,\n",
    "                    'max': None,\n",
    "                    'min': None,\n",
    "                    'show': False\n",
    "                }],\n",
    "                'legend': {\n",
    "                    'alignAsTable': True,\n",
    "                    'avg': True,\n",
    "                    'current': True,\n",
    "                    'hideEmpty': False,\n",
    "                    'hideZero': False,\n",
    "                    'max': True,\n",
    "                    'min': True,\n",
    "                    'rightSide': True,\n",
    "                    'show': True,\n",
    "                    'sortDesc': True,\n",
    "                    'sort': 'total',\n",
    "                    'total': True,\n",
    "                    'values': True\n",
    "                },\n",
    "                'gridPos': {\n",
    "                    'h': 8,\n",
    "                    'w': 12,\n",
    "                    'x': 0,\n",
    "                    'y': 0\n",
    "                },\n",
    "                'tooltip': {\n",
    "                    'shared': True,\n",
    "                    'sort': 0,\n",
    "                    'value_type': 'individual'\n",
    "                },\n",
    "                'links': [],\n",
    "                'maxDataPoints': 100,\n",
    "                'nullPointMode': 'null',\n",
    "                'pointradius': 5,\n",
    "                'stack': False,\n",
    "                'steppedLine': False,\n",
    "                'timeFrom': None,\n",
    "                'timeShift': None,\n",
    "                'options': {\n",
    "                    'showThresholdLabels': False,\n",
    "                    'showThresholdMarkers': True\n",
    "                },\n",
    "                'pluginVersion': '7.4.3',\n",
    "                'thresholds': []\n",
    "            }\n",
    "        if \"type1\" in type_pattern:\n",
    "            panels1.append(p)\n",
    "        else:\n",
    "            panels2.append(p)\n",
    "    panels1.extend(panels2)\n",
    "    ## dashboard metadata\n",
    "    dashboard_payload = {\n",
    "        'dashboard': {\n",
    "            'id': None,\n",
    "            'uid': dashboard_uid,\n",
    "            'title': dashboard_title,\n",
    "            'tags': dashboard_tags,\n",
    "            'timezone': 'browser',\n",
    "            'schemaVersion': 22,\n",
    "            'version': 0,\n",
    "            'refresh': '30s',\n",
    "            'time': {\n",
    "                'from': 'now-1h',\n",
    "                'to': 'now'\n",
    "            },\n",
    "            'panels': panels1\n",
    "        },\n",
    "        'folderId': 34,\n",
    "        'overwrite': False\n",
    "    }\n",
    "    return dashboard_payload\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b53291a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from grafana_dashboard_utils import get_grafana_dashboard_payload\n",
    "\n",
    "dashboard_payload = get_grafana_dashboard_payload(dashboard_payload_info, \"test_uid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98735357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"dashboard\": {\"id\": null, \"uid\": \"test_uid\", \"title\": \"Opni-metricAI\", \"tags\": [\"Opni-metricAI\"], \"timezone\": \"browser\", \"schemaVersion\": 22, \"version\": 0, \"refresh\": \"30s\", \"time\": {\"from\": \"now-1h\", \"to\": \"now\"}, \"panels\": [{\"datasource\": \"default\", \"gridPos\": {\"h\": 1, \"w\": 24, \"x\": 0, \"y\": 0}, \"id\": null, \"panels\": [], \"targets\": [{\"datasource\": \"default\", \"refId\": \"A\"}], \"title\": \"Type1\", \"type\": \"row\"}, {\"id\": null, \"type\": \"graph\", \"title\": \"YBtitle\", \"datasource\": \"default\", \"targets\": [{\"refId\": \"A\", \"expr\": \"sum(rate(container_fs_usage_bytes{namespace=\\\\\"default\\\\\"}[2m])) by (pod)\"}], \"xaxis\": {\"show\": true}, \"yaxes\": [{\"format\": \"short\", \"label\": \"Count\", \"logBase\": 1, \"max\": null, \"min\": 0, \"show\": true}, {\"format\": \"short\", \"label\": null, \"logBase\": 1, \"max\": null, \"min\": null, \"show\": false}], \"legend\": {\"alignAsTable\": true, \"avg\": true, \"current\": true, \"hideEmpty\": false, \"hideZero\": false, \"max\": true, \"min\": true, \"rightSide\": true, \"show\": true, \"sortDesc\": true, \"sort\": \"total\", \"total\": true, \"values\": true}, \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0, \"y\": 0}, \"tooltip\": {\"shared\": true, \"sort\": 0, \"value_type\": \"individual\"}, \"links\": [], \"maxDataPoints\": 100, \"nullPointMode\": \"null\", \"pointradius\": 5, \"stack\": false, \"steppedLine\": false, \"timeFrom\": null, \"timeShift\": null, \"options\": {\"showThresholdLabels\": false, \"showThresholdMarkers\": true}, \"pluginVersion\": \"7.4.3\", \"thresholds\": []}, {\"datasource\": \"default\", \"gridPos\": {\"h\": 1, \"w\": 24, \"x\": 0, \"y\": 0}, \"id\": null, \"panels\": [], \"targets\": [{\"datasource\": \"default\", \"refId\": \"A\"}], \"title\": \"Type2\", \"type\": \"row\"}]}, \"folderId\": 34, \"overwrite\": false}'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "form_payload1 = [(\"type1_\", \"YBtitle\", f'sum(rate(container_fs_usage_bytes{{namespace=\"default\"}}[2m])) by (pod)')]\n",
    "d_payload = get_grafana_dashboard_payload(form_payload1, \"test_uid\")\n",
    "json.dumps(d_payload)\n",
    "# d_payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "534506e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dashboard created successfully\n"
     ]
    }
   ],
   "source": [
    "create_dashboard(dashboard_payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19a90e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dashboard deleted successfully\n"
     ]
    }
   ],
   "source": [
    "remove_dashboard(\"dynamic-metricAI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36a397fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder ID: 34, Folder Title: Dynamic Folder\n"
     ]
    }
   ],
   "source": [
    "def create_folder():\n",
    "\n",
    "    # Grafana API endpoint for creating a folder\n",
    "    create_folder_url = grafana_url + '/folders'\n",
    "\n",
    "    # Folder name and parent folder ID\n",
    "    folder_name = 'Dynamic Folder'\n",
    "    parent_folder_id = 0\n",
    "\n",
    "    data = {\n",
    "        'title': folder_name,\n",
    "        'parentId': parent_folder_id\n",
    "    }\n",
    "\n",
    "    # Send the HTTP request to create the folder\n",
    "    response = requests.post(create_folder_url, headers=headers, json=data)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        print('Folder created successfully.')\n",
    "    else:\n",
    "        print('Error creating folder.')\n",
    "        print(response.content)\n",
    "\n",
    "def list_folder():\n",
    "    get_folders_url = grafana_url + '/folders'\n",
    "    response = requests.get(get_folders_url, headers=headers)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Parse the response JSON\n",
    "        folders = response.json()\n",
    "\n",
    "        # Print the ID and title of each folder\n",
    "        for folder in folders:\n",
    "            print(f\"Folder ID: {folder['id']}, Folder Title: {folder['title']}\")\n",
    "    else:\n",
    "        print('Error getting folder list.')\n",
    "        print(response.content)\n",
    "\n",
    "list_folder()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38metric",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "12743c56a1c6fb9d573a46d6810fe43abfc03eb020d53abd820a2eab96377291"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
